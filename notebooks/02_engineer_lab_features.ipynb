{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d537dda8",
   "metadata": {},
   "source": [
    "# 02 — Engineer Lab Features (First 24h Window)\n",
    "\n",
    "**Project:** Early ICU Mortality Prediction Using Structured EHR Data  \n",
    "**Dataset:** MIMIC-IV Clinical Database Demo (v2.2)\n",
    "\n",
    "## Goal of this notebook\n",
    "Create a **model-ready feature table** from laboratory measurements.\n",
    "\n",
    "We will:\n",
    "1. Load the cohort table created in `01_build_icustay_cohort.ipynb`\n",
    "2. Load `labevents`\n",
    "3. **Filter labs to the leakage-safe window:** `charttime <= prediction_time`  \n",
    "   (and optionally `charttime >= intime` to stay within the ICU stay)\n",
    "4. Aggregate lab results into features per ICU stay\n",
    "5. Save:\n",
    "   - `lab_features_24h.csv`\n",
    "   - `dataset_model_ready.csv` (cohort + labs)\n",
    "\n",
    "## Inputs\n",
    "- `cohort_icustay_mortality.csv`\n",
    "- `labevents.csv`\n",
    "\n",
    "## Outputs\n",
    "- `lab_features_24h.csv`\n",
    "- `dataset_model_ready.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "import sys, platform\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b05359",
   "metadata": {},
   "source": [
    "## 1) Locate files and load cohort + labevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\".\")\n",
    "\n",
    "# If not found in current directory, fall back to /mnt/data (common in hosted notebooks)\n",
    "if not (DATA_DIR / \"cohort_icustay_mortality.csv\").exists():\n",
    "    alt = Path(\"/mnt/data\")\n",
    "    if (alt / \"cohort_icustay_mortality.csv\").exists():\n",
    "        DATA_DIR = alt\n",
    "\n",
    "COHORT_PATH = DATA_DIR / \"cohort_icustay_mortality.csv\"\n",
    "LABEVENTS_PATH = DATA_DIR / \"labevents.csv\"\n",
    "\n",
    "print(\"Using DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"Cohort path:\", COHORT_PATH.resolve())\n",
    "print(\"Labevents path:\", LABEVENTS_PATH.resolve())\n",
    "\n",
    "cohort = pd.read_csv(COHORT_PATH)\n",
    "labevents = pd.read_csv(LABEVENTS_PATH)\n",
    "\n",
    "print(\"\\nLoaded:\")\n",
    "print(\"  cohort:\", cohort.shape)\n",
    "print(\"  labevents:\", labevents.shape)\n",
    "\n",
    "display(cohort.head(5))\n",
    "display(labevents.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0306cb",
   "metadata": {},
   "source": [
    "## 2) Parse timestamps and validate required columns\n",
    "\n",
    "We need:\n",
    "- From cohort: `subject_id`, `hadm_id`, `stay_id`, `intime`, `prediction_time`, `label_mortality`\n",
    "- From labs: `subject_id`, `hadm_id`, `itemid`, `charttime`, `valuenum`\n",
    "\n",
    "We will primarily use `valuenum` for numeric labs. (Some rows may have non-numeric `value`; those are ignored in this baseline.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cohort = {\"subject_id\", \"hadm_id\", \"stay_id\", \"intime\", \"prediction_time\", \"label_mortality\"}\n",
    "required_labs = {\"subject_id\", \"hadm_id\", \"itemid\", \"charttime\", \"valuenum\"}\n",
    "\n",
    "missing_cohort = required_cohort - set(cohort.columns)\n",
    "missing_labs = required_labs - set(labevents.columns)\n",
    "\n",
    "assert not missing_cohort, f\"Cohort missing: {missing_cohort}\"\n",
    "assert not missing_labs, f\"Labevents missing: {missing_labs}\"\n",
    "\n",
    "# Parse datetimes\n",
    "cohort[\"intime\"] = pd.to_datetime(cohort[\"intime\"], errors=\"coerce\")\n",
    "cohort[\"prediction_time\"] = pd.to_datetime(cohort[\"prediction_time\"], errors=\"coerce\")\n",
    "\n",
    "labevents[\"charttime\"] = pd.to_datetime(labevents[\"charttime\"], errors=\"coerce\")\n",
    "\n",
    "# Ensure numeric valuenum\n",
    "labevents[\"valuenum\"] = pd.to_numeric(labevents[\"valuenum\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Parsed times and coerced numeric values ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7154c3",
   "metadata": {},
   "source": [
    "## 3) Link labs to ICU stays and enforce the 24h leakage-safe window\n",
    "\n",
    "### Important notes\n",
    "- `labevents` is recorded at the **hospital admission** level (`hadm_id`), not the ICU-stay level.\n",
    "- An admission can have multiple ICU stays.\n",
    "- We attach labs to each ICU stay by joining on (`subject_id`, `hadm_id`) then filtering by time.\n",
    "\n",
    "### Window definition (default)\n",
    "- Keep labs where:  \n",
    "  `intime <= charttime <= prediction_time`  \n",
    "This ensures we only use labs available from ICU admission through the first 24 hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join labs to cohort using admission identifiers\n",
    "labs_joined = labevents.merge(\n",
    "    cohort[[\"subject_id\", \"hadm_id\", \"stay_id\", \"intime\", \"prediction_time\"]],\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"many_to_many\"\n",
    ")\n",
    "\n",
    "print(\"Joined labs rows:\", labs_joined.shape)\n",
    "\n",
    "# Filter to leakage-safe window\n",
    "labs_window = labs_joined[\n",
    "    (labs_joined[\"charttime\"].notna()) &\n",
    "    (labs_joined[\"intime\"].notna()) &\n",
    "    (labs_joined[\"prediction_time\"].notna()) &\n",
    "    (labs_joined[\"charttime\"] >= labs_joined[\"intime\"]) &\n",
    "    (labs_joined[\"charttime\"] <= labs_joined[\"prediction_time\"])\n",
    "].copy()\n",
    "\n",
    "print(\"Labs in 0-24h ICU window:\", labs_window.shape)\n",
    "\n",
    "# Optional: keep only numeric labs for baseline\n",
    "labs_window = labs_window[labs_window[\"valuenum\"].notna()].copy()\n",
    "print(\"Labs in window with numeric valuenum:\", labs_window.shape)\n",
    "\n",
    "display(labs_window[[\"stay_id\", \"itemid\", \"charttime\", \"valuenum\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bbd56",
   "metadata": {},
   "source": [
    "### Leakage sanity check\n",
    "\n",
    "We should have **zero** lab events with `charttime > prediction_time` after filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c18327",
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_count = (labs_window[\"charttime\"] > labs_window[\"prediction_time\"]).sum()\n",
    "print(\"Leakage events (charttime > prediction_time):\", int(leak_count))\n",
    "assert leak_count == 0, \"Leakage detected: some labs occur after prediction_time\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fc77b",
   "metadata": {},
   "source": [
    "## 4) Choose which labs to featurize\n",
    "\n",
    "MIMIC has many lab `itemid`s. For a baseline model, we can:\n",
    "- take the **top N most frequently measured labs** in the 24h window, and featurize those.\n",
    "\n",
    "This avoids overly sparse feature matrices on small datasets like the demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top labs by frequency in the window\n",
    "lab_counts = labs_window[\"itemid\"].value_counts()\n",
    "display(lab_counts.head(20))\n",
    "\n",
    "TOP_N = 30  # good starting point for demo scale\n",
    "top_itemids = lab_counts.head(TOP_N).index.tolist()\n",
    "print(f\"Using TOP_N={TOP_N} labs -> {len(top_itemids)} itemids\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1990eb1",
   "metadata": {},
   "source": [
    "## 5) Aggregate lab measurements into per-stay features\n",
    "\n",
    "For each (`stay_id`, `itemid`), compute:\n",
    "- `min`, `max`, `mean`, `std`, `count`\n",
    "\n",
    "Then pivot so each `stay_id` becomes a single row with many columns like:\n",
    "- `lab_50882_mean`, `lab_50882_min`, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_top = labs_window[labs_window[\"itemid\"].isin(top_itemids)].copy()\n",
    "\n",
    "agg = (\n",
    "    labs_top\n",
    "    .groupby([\"stay_id\", \"itemid\"])[\"valuenum\"]\n",
    "    .agg([\"min\", \"max\", \"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(agg.head(10))\n",
    "print(\"Aggregated rows:\", agg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2085f20",
   "metadata": {},
   "source": [
    "### Pivot into a wide feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wide features: columns = f\"lab_{itemid}_{stat}\"\n",
    "features_wide = agg.pivot(index=\"stay_id\", columns=\"itemid\")\n",
    "features_wide.columns = [f\"lab_{int(itemid)}_{stat}\" for stat, itemid in features_wide.columns]\n",
    "features_wide = features_wide.reset_index()\n",
    "\n",
    "print(\"Wide feature table:\", features_wide.shape)\n",
    "display(features_wide.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f024f1",
   "metadata": {},
   "source": [
    "## 6) Add missingness indicators (very useful in EHR)\n",
    "\n",
    "Missingness itself is predictive in clinical data.  \n",
    "We add a per-lab indicator: 1 if that lab was measured at least once in the window, else 0.\n",
    "\n",
    "We define \"measured\" as `count > 0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missingness indicators from count columns\n",
    "count_cols = [c for c in features_wide.columns if c.endswith(\"_count\") and c.startswith(\"lab_\")]\n",
    "miss_indicators = features_wide[[\"stay_id\"]].copy()\n",
    "\n",
    "for c in count_cols:\n",
    "    base = c.replace(\"_count\", \"\")\n",
    "    miss_indicators[f\"{base}_measured\"] = (features_wide[c].fillna(0) > 0).astype(\"int8\")\n",
    "\n",
    "print(\"Missingness indicators:\", miss_indicators.shape)\n",
    "display(miss_indicators.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79dfbd",
   "metadata": {},
   "source": [
    "## 7) Merge features back onto the cohort and create a model-ready dataset\n",
    "\n",
    "We keep:\n",
    "- identifiers + label from cohort\n",
    "- lab feature columns\n",
    "- measured indicators\n",
    "\n",
    "No imputation here yet — that belongs in the modeling notebook/pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c31212",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_features = features_wide.merge(miss_indicators, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "dataset = cohort.merge(lab_features, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "print(\"Dataset (cohort + lab features):\", dataset.shape)\n",
    "display(dataset.head(5))\n",
    "\n",
    "# Quick: how many stays have at least one lab feature?\n",
    "feature_cols = [c for c in dataset.columns if c.startswith(\"lab_\")]\n",
    "has_any = dataset[feature_cols].notna().any(axis=1).mean()\n",
    "print(f\"Fraction of ICU stays with ANY lab feature (non-null): {has_any:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a885ca4",
   "metadata": {},
   "source": [
    "## 8) Save artifacts\n",
    "\n",
    "- `lab_features_24h.csv`: features only (keyed by stay_id)\n",
    "- `dataset_model_ready.csv`: cohort + label + features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d868408",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_FEATURES_PATH = Path(\"lab_features_24h.csv\")\n",
    "DATASET_PATH = Path(\"dataset_model_ready.csv\")\n",
    "\n",
    "lab_features.to_csv(LAB_FEATURES_PATH, index=False)\n",
    "dataset.to_csv(DATASET_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", LAB_FEATURES_PATH.resolve())\n",
    "print(\" \", DATASET_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc71894",
   "metadata": {},
   "source": [
    "## Next notebook\n",
    "**`03_train_baseline_model.ipynb`**\n",
    "- Load `dataset_model_ready.csv`\n",
    "- Split train/test by ICU stay (and later by time if using full data)\n",
    "- Build a preprocessing + model pipeline:\n",
    "  - imputation\n",
    "  - scaling (for linear models)\n",
    "  - baseline logistic regression\n",
    "- Evaluate with ROC-AUC and PR-AUC\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
